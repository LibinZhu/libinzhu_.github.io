---
permalink: /
title: "academicpages is a ready-to-fork GitHub Pages template for academic personal websites"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## About me
I am currently a Ph.D. candidate in Computer Science and Engineering at University of California, San Diego (UCSD), luckily adivised by  [Mikhail Belkin](http://misha.belkin-wang.org/). I received my BS in Mathematics from Zhejiang University. 

I am interested in theoretical machine learning problems. Recently, I have focused on understanding optimization and generalization for wide neural networks. One of the interesting questions is *"Can Neural Tangent Kernel (NTK) answer the mystery of neural networks?"*


## Papers 
- A Banerjee, P Cisneros-Velarde, L Zhu, M Belkin, [Restricted Strong Convexity of Deep Learning Models with Smooth Activations](https://arxiv.org/pdf/2209.15106.pdf). ICLR 2023.
- L Zhu, P Pandit, M Belkin, [A note on Linear Bottleneck networks and their Transition to Multilinearity](https://arxiv.org/pdf/2206.15058.pdf). Pre-printed.
- L Zhu, C Liu, A Radhakrishnan, M Belkin, [Quadratic models for understanding neural network dynamics](https://arxiv.org/pdf/2205.11787.pdf). Pre-printed.
- L Zhu, C Liu, M Belkin, [Transition to Linearity of General Neural Networks with Directed Acyclic Graph Architecture](https://arxiv.org/pdf/2205.11786.pdf). NeurIPS 2022. 
- C Liu, L Zhu, M Belkin, [Transition to Linearity of Wide Neural Networks is an Emerging Property of Assembling Weak Models](https://arxiv.org/pdf/2203.05104.pdf). ICLR 2021 (Spotlight). 
- C Liu, L Zhu, M Belkin, [On the linearity of large non-linear models: when and why the tangent kernel is constant](https://arxiv.org/pdf/2010.01092.pdf). NeurIPS 2020 (Spotlight). 
- C Liu, L Zhu, M Belkin, [Loss landscapes and optimization in over-parameterized non-linear systems and neural networks](https://arxiv.org/pdf/2003.00307.pdf). Applied and Computational Harmonic Analysis (ACHA).
